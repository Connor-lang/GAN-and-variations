{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "I5PzzuVpEyHK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sys\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "from torch.autograd import Variable\n",
        "import itertools\n",
        "from collections import OrderedDict\n",
        "import time\n",
        "import functools\n",
        "from torch.nn import init\n",
        "import ntpath"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KBD2zRS2rsGz"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 1\n",
        "GPU_IDS = [i for i in range(torch.cuda.device_count())]\n",
        "DEVICE = torch.device('cuda:{}'.format(GPU_IDS[0])) if GPU_IDS else torch.device('cpu')\n",
        "LEARNING_RATE = 1e-5\n",
        "LAMBDA_IDENTITY = 0.5\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_WORKERS = 4\n",
        "NUM_EPOCHS = 100\n",
        "LOAD_MODEL = False\n",
        "SAVE_MODEL = True\n",
        "CHECKPOINT_GEN_H = \"genh.pth.tar\"\n",
        "CHECKPOINT_GEN_Z = \"genz.pth.tar\"\n",
        "CHECKPOINT_CRITIC_H = \"critich.pth.tar\"\n",
        "CHECKPOINT_CRITIC_Z = \"criticz.pth.tar\"\n",
        "\n",
        "IMG_EXTENSIONS = [\n",
        "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
        "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
        "]\n",
        "\n",
        "if (len(GPU_IDS) > 0):\n",
        "  torch.cuda.set_device(f'cuda:{GPU_IDS[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOlsp5iAdjuI",
        "outputId": "434bbb56-4e02-4b24-eb5a-044c81ee4179"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "kYpWsT_BQNgS"
      },
      "outputs": [],
      "source": [
        "def get_transform():\n",
        "  transform_list = []\n",
        "  zoom = 1 + 0.1 * random.randint(0, 4)\n",
        "  osize = [int(400 * zoom), int(600 * zoom)]\n",
        "  transform_list.append(transforms.Resize(osize, transforms.functional.InterpolationMode.BICUBIC))\n",
        "  transform_list.append(transforms.RandomCrop(256))\n",
        "  transform_list.append(transforms.RandomHorizontalFlip())\n",
        "  transform_list += [transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                            (0.5, 0.5, 0.5))]\n",
        "  return transforms.Compose(transform_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zrt5WV54LEsu"
      },
      "outputs": [],
      "source": [
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "k2V6GLzWKgdb"
      },
      "outputs": [],
      "source": [
        "def store_dataset(dir):\n",
        "  images = []\n",
        "  all_path = []\n",
        "  assert os.path.isdir(dir), '%s is not a valid directory' %dir\n",
        "\n",
        "  for root, _, fnames in sorted(os.walk(dir)):\n",
        "    for fname in fnames: \n",
        "      if is_image_file(fname):\n",
        "        path = os.path.join(root, fname)\n",
        "        img = Image.open(path).convert('RGB')\n",
        "        images.append(img)\n",
        "        all_path.append(path)\n",
        "  return images, all_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jkKEEXpWGqXT"
      },
      "outputs": [],
      "source": [
        "def CreateDataLoader():\n",
        "  data_loader = CustomDatasetDataLoader()\n",
        "  print(data_loader.name())\n",
        "  data_loader.initialize()\n",
        "  return data_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "XygFw1NnKsBd"
      },
      "outputs": [],
      "source": [
        "gpu_ids = \"0\"\n",
        "str_ids = gpu_ids.split(',')\n",
        "gpu_ids = []\n",
        "for str_id in str_ids:\n",
        "  id = int(str_id)\n",
        "  if id >= 0:\n",
        "    gpu_ids.append(id)\n",
        "if(len(gpu_ids)) > 0:\n",
        "  torch.cuda.set_device(gpu_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WA1Pi7wAHBdo"
      },
      "outputs": [],
      "source": [
        "class CustomDatasetDataLoader():\n",
        "    def name(self):\n",
        "        return 'CustomDatasetDataLoader'\n",
        "\n",
        "    def initialize(self):\n",
        "        self.dataset = UnalignedDataset(\"/content/drive/MyDrive/final_dataset/trainA\", \"/content/drive/MyDrive/final_dataset/trainB\")\n",
        "        self.dataloader = torch.utils.data.DataLoader(\n",
        "            self.dataset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=not True,\n",
        "            num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "    def load_data(self):\n",
        "        return self.dataloader\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.dataset), float(\"inf\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Vq8SWObrtEYN"
      },
      "outputs": [],
      "source": [
        "class ImagePool():\n",
        "    def __init__(self, pool_size):\n",
        "        self.pool_size = pool_size\n",
        "        if self.pool_size > 0:\n",
        "            self.num_imgs = 0\n",
        "            self.images = []\n",
        "\n",
        "    def query(self, images):\n",
        "        if self.pool_size == 0:\n",
        "            return images\n",
        "        return_images = []\n",
        "        for image in images.data:\n",
        "            image = torch.unsqueeze(image, 0)\n",
        "            if self.num_imgs < self.pool_size:\n",
        "                self.num_imgs = self.num_imgs + 1\n",
        "                self.images.append(image)\n",
        "                return_images.append(image)\n",
        "            else:\n",
        "                p = random.uniform(0, 1)\n",
        "                if p > 0.5:\n",
        "                    random_id = random.randint(0, self.pool_size-1)\n",
        "                    tmp = self.images[random_id].clone()\n",
        "                    self.images[random_id] = image\n",
        "                    return_images.append(tmp)\n",
        "                else:\n",
        "                    return_images.append(image)\n",
        "        return_images = Variable(torch.cat(return_images, 0))\n",
        "        return return_images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sRGBtoLin(colorChannel):\n",
        "  return torch.where(colorChannel <= 0.4045, colorChannel / 12.92, ((colorChannel + 0.055) / 1.055) ** 2.4)"
      ],
      "metadata": {
        "id": "vTMZaM2fpPNF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def YtoLstar(Y):\n",
        "  return torch.where(Y <= 216/24389, Y * (24389/27), (Y ** 1/3) * 116 - 16) "
      ],
      "metadata": {
        "id": "w-iKAPHmppP8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "up7RsCESHoEJ"
      },
      "outputs": [],
      "source": [
        "class UnalignedDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, dir_A, dir_B):\n",
        "        self.dir_A = dir_A\n",
        "        self.dir_B = dir_B\n",
        "        self.transform = get_transform()\n",
        "\n",
        "        self.A_imgs, self.A_paths = store_dataset(self.dir_A)\n",
        "        self.B_imgs, self.B_paths = store_dataset(self.dir_B)\n",
        "        self.length_dataset = max(len(self.A_imgs), len(self.B_imgs))\n",
        "        self.A_size = len(self.A_paths)\n",
        "        self.B_size = len(self.B_paths)\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.length_dataset\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      A_img = self.A_imgs[index % self.A_size]\n",
        "      B_img = self.B_imgs[index % self.B_size]\n",
        "      A_path = self.A_paths[index % self.A_size]\n",
        "      B_path = self.B_paths[index % self.B_size]\n",
        "\n",
        "      A_img = self.transform(A_img)\n",
        "      B_img = self.transform(B_img)\n",
        "\n",
        "      input_img = A_img\n",
        "      B_img = (B_img + 1)/2.\n",
        "      B_img = (B_img - torch.min(B_img))/(torch.max(B_img) - torch.min(B_img))\n",
        "      B_img = B_img * 2. - 1\n",
        "      r, g, b = input_img[0] + 1, input_img[1] + 1, input_img[2] + 1\n",
        "\n",
        "      A_gray = 1. - (0.299*r+0.587*g+0.114*b)/2.\n",
        "      A_gray = torch.unsqueeze(A_gray, 0)\n",
        "\n",
        "      # degamma_R = sRGBtoLin(r)\n",
        "      # degamma_G = sRGBtoLin(g)\n",
        "      # degamma_B = sRGBtoLin(b)\n",
        "      # Y = (0.2126 * degamma_R + 0.7152 * degamma_G + 0.0722 * degamma_B)\n",
        "      # A_gray = YtoLstar(Y)\n",
        "\n",
        "      return {'A': A_img, 'B': B_img, 'A_gray': A_gray, 'input_img': input_img,\n",
        "                'A_paths': A_path, 'B_paths': B_path}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Y9H70wfihgi2"
      },
      "outputs": [],
      "source": [
        "def get_norm_layer(norm_type='instance'):\n",
        "    if norm_type == 'batch':\n",
        "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
        "    elif norm_type == 'instance':\n",
        "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
        "    else:\n",
        "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
        "    return norm_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "mAStqgdBhiv6"
      },
      "outputs": [],
      "source": [
        "def init_weights(net, init_type='normal', init_gain=0.02):\n",
        "    def init_func(m): \n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "            if init_type == 'normal':\n",
        "                init.normal_(m.weight.data, 0.0, init_gain)\n",
        "            elif init_type == 'xavier':\n",
        "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
        "            elif init_type == 'kaiming':\n",
        "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "            elif init_type == 'orthogonal':\n",
        "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
        "            else:\n",
        "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('BatchNorm2d') != -1:  \n",
        "            init.normal_(m.weight.data, 1.0, init_gain)\n",
        "            init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    print('initialize network with %s' % init_type)\n",
        "    net.apply(init_func)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "EaRcxFBRgXZS"
      },
      "outputs": [],
      "source": [
        "def init_net(net, init_type='normal', init_gain=0.02):\n",
        "    if len(GPU_IDS) > 0:\n",
        "        assert(torch.cuda.is_available())\n",
        "        net.to(GPU_IDS[0])\n",
        "        net = torch.nn.DataParallel(net, device_ids=[0])  \n",
        "    init_weights(net, init_type, init_gain=init_gain)\n",
        "    return net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HCeItyregIpy"
      },
      "outputs": [],
      "source": [
        "def define_G(input_nc, output_nc, ngf, norm='batch', use_dropout=False, init_type='normal', init_gain=0.02):\n",
        "  net = None\n",
        "  norm_layer = get_norm_layer(norm_type=norm)\n",
        "  net = UnetGenerator(input_nc, output_nc, 8, ngf, norm_layer=norm_layer, use_dropout=use_dropout)\n",
        "  return init_net(net, init_type, init_gain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xM9HjAyIv2CP"
      },
      "outputs": [],
      "source": [
        "def define_D(input_nc, ndf, n_layers_D=3, norm='batch', init_type='normal', init_gain=0.02):\n",
        "  net = None\n",
        "  norm_layer = get_norm_layer(norm_type=norm)\n",
        "  net = NLayerDiscriminator(input_nc, ndf, n_layers=3, norm_layer=norm_layer)\n",
        "  return init_net(net, init_type, init_gain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JiKYFtEGExl5"
      },
      "outputs": [],
      "source": [
        "class UnetSkipConnectionBlock(nn.Module):\n",
        "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
        "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
        "        super(UnetSkipConnectionBlock, self).__init__()\n",
        "        self.outermost = outermost\n",
        "        if type(norm_layer) == functools.partial:\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "        if input_nc is None:\n",
        "            input_nc = outer_nc\n",
        "        downconv = nn.Conv2d(outer_nc, inner_nc, kernel_size=4,\n",
        "                             stride=2, padding=1, bias=use_bias)\n",
        "        downrelu = nn.LeakyReLU(0.2, True)\n",
        "        downnorm = norm_layer(inner_nc)\n",
        "        uprelu = nn.ReLU(True)\n",
        "        upnorm = norm_layer(outer_nc)\n",
        "\n",
        "        if outermost:\n",
        "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
        "                                        kernel_size=4, stride=2,\n",
        "                                        padding=1)\n",
        "            down = [downconv]\n",
        "            up = [uprelu, upconv, nn.Tanh()]\n",
        "            model = down + [submodule] + up\n",
        "        elif innermost:\n",
        "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n",
        "                                        kernel_size=4, stride=2,\n",
        "                                        padding=1, bias=use_bias)\n",
        "            down = [downrelu, downconv]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            model = down + up\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
        "                                        kernel_size=4, stride=2,\n",
        "                                        padding=1, bias=use_bias)\n",
        "            down = [downrelu, downconv, downnorm]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "\n",
        "            if use_dropout:\n",
        "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
        "            else:\n",
        "                model = down + [submodule] + up\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:\n",
        "            return torch.cat([x, self.model(x)], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vMRy5PZfmemt"
      },
      "outputs": [],
      "source": [
        "class SkipModule(nn.Module):\n",
        "    def __init__(self, submodule):\n",
        "        super(SkipModule, self).__init__()\n",
        "        self.submodule = submodule\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.submodule(x)\n",
        "        return 0.8*x + latent, latent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4LW7elgPeFeE"
      },
      "outputs": [],
      "source": [
        "class UnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, num_downs, ngf=64,\n",
        "                 norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
        "        super(UnetGenerator, self).__init__()\n",
        "\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)\n",
        "        for i in range(num_downs - 5):\n",
        "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        self.model = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)\n",
        "\n",
        "    def forward(self, input):\n",
        "      return self.model(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VmBvu-JYi1Ug"
      },
      "outputs": [],
      "source": [
        "class NLayerDiscriminator(nn.Module):\n",
        "  def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
        "    super(NLayerDiscriminator, self).__init__()\n",
        "    if type(norm_layer) == functools.partial:\n",
        "      use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "    else:\n",
        "      use_bias = norm_layer == nn.InstanceNorm2d\n",
        "\n",
        "    kw = 4\n",
        "    padw = int(np.ceil((kw-1)/2))\n",
        "    sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
        "\n",
        "    nf_mult = 1\n",
        "    nf_mult_prev = 1\n",
        "    for n in range(1, n_layers):\n",
        "      nf_mult_prev = nf_mult\n",
        "      nf_mult = min(2**n, 8)\n",
        "      sequence += [\n",
        "          nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
        "          norm_layer(ndf * nf_mult),\n",
        "          nn.LeakyReLU(0.2, True)\n",
        "      ]\n",
        "\n",
        "    nf_mult_prev = nf_mult\n",
        "    nf_mult = min(2**n_layers, 8)\n",
        "    sequence += [\n",
        "        nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
        "        norm_layer(ndf * nf_mult),\n",
        "        nn.LeakyReLU(0.2, True)\n",
        "    ]\n",
        "\n",
        "    sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n",
        "    \n",
        "    self.model = nn.Sequential(*sequence)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_7IdwlCpsmYp"
      },
      "outputs": [],
      "source": [
        "class GANLoss(nn.Module):\n",
        "    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0):\n",
        "        super(GANLoss, self).__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
        "        if use_lsgan:\n",
        "            self.loss = nn.MSELoss()\n",
        "        else:\n",
        "            self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def get_target_tensor(self, prediction, target_is_real):\n",
        "        if target_is_real:\n",
        "            target_tensor = self.real_label\n",
        "        else:\n",
        "            target_tensor = self.fake_label\n",
        "        return target_tensor.expand_as(prediction)\n",
        "\n",
        "    def __call__(self, prediction, target_is_real):\n",
        "        target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
        "        return self.loss(prediction, target_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "zCj3-7j6xFt9"
      },
      "outputs": [],
      "source": [
        "def print_network(net):\n",
        "    num_params = 0\n",
        "    for param in net.parameters():\n",
        "        num_params += param.numel()\n",
        "    print(net)\n",
        "    print('Total number of parameters: %d' % num_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "8cOA4tOsK_Kw"
      },
      "outputs": [],
      "source": [
        "def tensor2im(image_tensor, imtype=np.uint8):\n",
        "    if not isinstance(image_tensor, np.ndarray):\n",
        "        if isinstance(image_tensor, torch.Tensor):  \n",
        "            image_tensor = image_tensor.data\n",
        "        else:\n",
        "            return image_tensor\n",
        "        image_numpy = image_tensor[0].cpu().float().numpy()  \n",
        "        if image_numpy.shape[0] == 1:  \n",
        "            image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  \n",
        "    else:  \n",
        "        image_numpy = image_tensor\n",
        "    return image_numpy.astype(imtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMtPlsNTLJxt",
        "outputId": "232cf0a9-8da9-4a55-a32e-d4978cc9ebfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CustomDatasetDataLoader\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "data_loader = CreateDataLoader()\n",
        "dataset = data_loader.load_data()\n",
        "dataset_size = len(data_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oJ6_SV0eTzI",
        "outputId": "134c64fd-dd71-48b9-c548-9b71a0b8b777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#training images = 1016\n"
          ]
        }
      ],
      "source": [
        "print('#training images = %d' % dataset_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "n2g8tlyykya3"
      },
      "outputs": [],
      "source": [
        "class CycleGANModel():\n",
        "  def __init__(self, batchSize = 1, fineSize = 256, input_nc=3, output_nc=3):\n",
        "    nb = batchSize\n",
        "    size = fineSize\n",
        "    self.netG_A = define_G(input_nc = 3, output_nc = 3, ngf = 64, norm = 'instance', use_dropout = not True, init_type = 'normal', init_gain = 0.02)\n",
        "    #self.netG_A = define_G(input_nc = 3, output_nc = 3, ngf = 64, norm = 'instance', use_dropout = not True, init_type = 'kaiming', init_gain = 0.02)\n",
        "    self.netG_B = define_G(input_nc = 3, output_nc = 3, ngf = 64, norm = 'instance', use_dropout = not True, init_type = 'normal', init_gain = 0.02)\n",
        "   \n",
        "    self.netD_A = define_D(input_nc =3, ndf=64, n_layers_D=3, norm='instance', init_type='normal', init_gain=0.2)\n",
        "    self.netD_B = define_D(input_nc =3, ndf=64, n_layers_D=3, norm='instance', init_type='normal', init_gain=0.2)\n",
        "    self.fake_A_pool = ImagePool(50)\n",
        "    self.fake_B_pool = ImagePool(50)\n",
        "\n",
        "    self.criterionGAN = GANLoss(use_lsgan = True).to(DEVICE)\n",
        "    self.criterionCycle = torch.nn.L1Loss()\n",
        "    self.criterionL1 = torch.nn.L1Loss()\n",
        "    self.criterionIdt = torch.nn.L1Loss()\n",
        "\n",
        "    self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()), \n",
        "                                        lr = LEARNING_RATE, betas = (0.5, 0.999))\n",
        "    self.optimizer_D_A = torch.optim.Adam(self.netD_A.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "    self.optimizer_D_B = torch.optim.Adam(self.netD_B.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "\n",
        "    \n",
        "    print('---------- Networks initialized -------------')\n",
        "    print_network(self.netG_A)\n",
        "    print_network(self.netG_B)\n",
        "    print_network(self.netD_A)\n",
        "    print_network(self.netD_B)\n",
        "    print('-----------------------------------------------')\n",
        "\n",
        "  def set_input(self, input):\n",
        "    self.real_A = input['A'].to(DEVICE)\n",
        "    self.real_B = input['B'].to(DEVICE)\n",
        "    self.image_paths = input['A_paths']\n",
        "    \n",
        "\n",
        "  def forward(self):\n",
        "    self.fake_B = self.netG_A(self.real_A)\n",
        "    self.rec_A = self.netG_B(self.fake_B)\n",
        "    self.fake_A = self.netG_B(self.real_B)\n",
        "    self.rec_B = self.netG_A(self.fake_A)\n",
        "\n",
        "  def predict(self):\n",
        "    self.real_A = Variable(self.input_A, volatile=True)\n",
        "    if self.opt.skip == 1:\n",
        "        self.fake_B, self.latent_real_A = self.netG_A.forward(self.real_A)\n",
        "    else:\n",
        "        self.fake_B = self.netG_A.forward(self.real_A)\n",
        "    self.rec_A = self.netG_B.forward(self.fake_B)\n",
        "\n",
        "    real_A = tensor2im(self.real_A.data)\n",
        "    fake_B = tensor2im(self.fake_B.data)\n",
        "    rec_A = tensor2im(self.rec_A.data)\n",
        "    return OrderedDict([('real_A', real_A), ('fake_B', fake_B), (\"rec_A\", rec_A)])\n",
        "\n",
        "  def get_image_paths(self):\n",
        "        return self.image_paths\n",
        "  \n",
        "  def backward_D_basic(self, netD, real, fake):\n",
        "    \n",
        "    pred_real = netD.forward(real)\n",
        "    loss_D_real = self.criterionGAN(pred_real, True)\n",
        "    \n",
        "    pred_fake = netD.forward(fake.detach())\n",
        "    loss_D_fake = self.criterionGAN(pred_fake, False)\n",
        "    \n",
        "    loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
        "\n",
        "    loss_D.backward()\n",
        "    return loss_D\n",
        "\n",
        "  def backward_D_A(self):\n",
        "      fake_B = self.fake_B_pool.query(self.fake_B)\n",
        "      self.loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n",
        "\n",
        "  def backward_D_B(self):\n",
        "      fake_A = self.fake_A_pool.query(self.fake_A)\n",
        "      self.loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n",
        "\n",
        "  def backward_G(self, epoch):\n",
        "    lambda_idt = 0.0\n",
        "    lambda_A = 10.0\n",
        "    lambda_B = 10.0\n",
        "    self.loss_idt_A = 0\n",
        "    self.loss_idt_B = 0\n",
        "\n",
        "    self.fake_B = self.netG_A.forward(self.real_A) \n",
        "    pred_fake = self.netD_A.forward(self.fake_B) \n",
        "    self.loss_G_A = self.criterionGAN(pred_fake, True) \n",
        "    self.L1_AB = self.criterionL1(self.fake_B, self.real_B) * 10.0\n",
        "\n",
        "    self.fake_A = self.netG_B.forward(self.real_B)\n",
        "    pred_fake = self.netD_B.forward(self.fake_A)\n",
        "\n",
        "    self.L1_BA = self.criterionL1(self.fake_A, self.real_A) * 10.0\n",
        "    self.loss_G_B = self.criterionGAN(pred_fake, True)\n",
        "\n",
        "    self.rec_A = self.netG_B.forward(self.fake_B)\n",
        "    self.loss_cycle_A = self.criterionCycle(self.rec_A, self.real_A) * lambda_A\n",
        "\n",
        "    self.rec_B = self.netG_A.forward(self.fake_A)\n",
        "    self.loss_cycle_B = self.criterionCycle(self.rec_B, self.real_B) * lambda_B\n",
        "\n",
        "    self.loss_G = self.loss_G_A + self.loss_G_B + self.loss_cycle_A + self.loss_cycle_B \n",
        "    \n",
        "    self.loss_G.backward()\n",
        "\n",
        "  def optimize_parameters(self, epoch):\n",
        "    \n",
        "    self.forward()\n",
        "\n",
        "    self.optimizer_G.zero_grad()\n",
        "    self.backward_G(epoch)\n",
        "    self.optimizer_G.step()\n",
        "    \n",
        "    self.optimizer_D_A.zero_grad()\n",
        "    self.backward_D_A()\n",
        "    self.optimizer_D_A.step()\n",
        "    \n",
        "    self.optimizer_D_B.zero_grad()\n",
        "    self.backward_D_B()\n",
        "    self.optimizer_D_B.step()\n",
        "   \n",
        "  def get_current_errors(self):\n",
        "    D_A = self.loss_D_A.data[0]\n",
        "    G_A = self.loss_G_A.data[0]\n",
        "    Cyc_A = self.loss_cycle_A.data[0]\n",
        "    D_B = self.loss_D_B.data[0]\n",
        "    G_B = self.loss_G_B.data[0]\n",
        "    Cyc_B = self.loss_cycle_B.data[0]\n",
        "    if self.lambda_A > 0.0:\n",
        "        return OrderedDict([('D_A', D_A), ('G_A', G_A), ('Cyc_A', Cyc_A),\n",
        "                            ('D_B', D_B), ('G_B', G_B), ('Cyc_B', Cyc_B)])\n",
        "    else:\n",
        "        return OrderedDict([('D_A', D_A), ('G_A', G_A), \n",
        "                            ('D_B', D_B), ('G_B', G_B)])\n",
        "        \n",
        "  def get_current_visuals(self):\n",
        "    real_A = tensor2im(self.real_A.data)\n",
        "    fake_B = tensor2im(self.fake_B.data)\n",
        "    latent_real_A = tensor2im(self.latent_real_A.data)\n",
        "    real_B = tensor2im(self.real_B.data)\n",
        "    fake_A = tensor2im(self.fake_A.data)\n",
        "\n",
        "    rec_A = tensor2im(self.rec_A.data)\n",
        "    rec_B = tensor2im(self.rec_B.data)\n",
        "    latent_fake_A = tensor2im(self.latent_fake_A.data)\n",
        "    return OrderedDict([('real_A', real_A), ('fake_B', fake_B), ('latent_real_A', latent_real_A), ('rec_A', rec_A), \n",
        "                        ('real_B', real_B), ('fake_A', fake_A), ('rec_B', rec_B), ('latent_fake_A', latent_fake_A)])\n",
        "    \n",
        "  def load_networks(self, epoch): \n",
        "    for name in ['G_A', 'G_B']:\n",
        "      if isinstance(name, str):\n",
        "          load_filename = '%s_net_%s.pth' % (epoch, name)\n",
        "          load_path = os.path.join('/content/checkpoints', load_filename)\n",
        "          net = getattr(self, 'net' + name)\n",
        "          if isinstance(net, torch.nn.DataParallel):\n",
        "              net = net.module\n",
        "          print('loading the model from %s' % load_path)\n",
        "          state_dict = torch.load(load_path, map_location=str(DEVICE))\n",
        "          if hasattr(state_dict, '_metadata'):\n",
        "              del state_dict._metadata\n",
        "          net.load_state_dict(state_dict)\n",
        "    \n",
        "  def setup(self):\n",
        "    load_suffix = 'latest'\n",
        "    self.load_networks(load_suffix)\n",
        "  \n",
        "  def eval(self):\n",
        "    for name in self.model_names:\n",
        "      if isinstance(name, str):\n",
        "        net = getattr(self, 'net' + name)\n",
        "        net.eval()\n",
        "\n",
        "  def compute_visuals(self):\n",
        "    pass\n",
        "\n",
        "  def get_current_visuals(self):\n",
        "    visual_ret = OrderedDict()\n",
        "    for name in ['real_A', 'fake_B', 'rec_A', 'real_B', 'fake_A', 'rec_B']:\n",
        "        if isinstance(name, str):\n",
        "            visual_ret[name] = getattr(self, name)\n",
        "    return visual_ret\n",
        "    \n",
        "  def test(self):\n",
        "    with torch.no_grad():\n",
        "      self.forward()\n",
        "      self.compute_visuals()\n",
        "    \n",
        "  def save_networks(self, epoch):\n",
        "    model_names = ['G_A', 'G_B', 'D_A', 'D_B']\n",
        "    for name in model_names:\n",
        "      if isinstance(name , str):\n",
        "        save_filename = '%s_net_%s.pth' % (epoch, name)\n",
        "        save_path = os.path.join('/content/checkpoints', save_filename)\n",
        "        net = getattr(self, 'net' + name)\n",
        "\n",
        "        if len(GPU_IDS) > 0 and torch.cuda.is_available():\n",
        "          torch.save(net.module.cpu().state_dict(), save_path)\n",
        "          net.cuda(GPU_IDS[0])\n",
        "        else:\n",
        "          torch.save(net.cpu().state_dict(), save_path)\n",
        "\n",
        "  def update_learning_rate(self):\n",
        "    lrd = 0.0001 / 100\n",
        "    lr = self.old_lr - lrd\n",
        "    for param_group in self.optimizer_D_A.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    for param_group in self.optimizer_D_B.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    for param_group in self.optimizer_G.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    print('update learning rate: %f -> %f' % (self.old_lr, lr))\n",
        "    self.old_lr = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSJFO1LW7fc6",
        "outputId": "492d112b-5993-48a6-8ed3-10200254ccbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "---------- Networks initialized -------------\n",
            "DataParallel(\n",
            "  (module): UnetGenerator(\n",
            "    (model): UnetSkipConnectionBlock(\n",
            "      (model): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "        (1): UnetSkipConnectionBlock(\n",
            "          (model): Sequential(\n",
            "            (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "            (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "            (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "            (3): UnetSkipConnectionBlock(\n",
            "              (model): Sequential(\n",
            "                (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                (3): UnetSkipConnectionBlock(\n",
            "                  (model): Sequential(\n",
            "                    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                    (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                    (3): UnetSkipConnectionBlock(\n",
            "                      (model): Sequential(\n",
            "                        (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                        (3): UnetSkipConnectionBlock(\n",
            "                          (model): Sequential(\n",
            "                            (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                            (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                            (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                            (3): UnetSkipConnectionBlock(\n",
            "                              (model): Sequential(\n",
            "                                (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                                (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                                (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                                (3): UnetSkipConnectionBlock(\n",
            "                                  (model): Sequential(\n",
            "                                    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                                    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                                    (2): ReLU(inplace=True)\n",
            "                                    (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                                    (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                                  )\n",
            "                                )\n",
            "                                (4): ReLU(inplace=True)\n",
            "                                (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                                (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                              )\n",
            "                            )\n",
            "                            (4): ReLU(inplace=True)\n",
            "                            (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                            (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                          )\n",
            "                        )\n",
            "                        (4): ReLU(inplace=True)\n",
            "                        (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                      )\n",
            "                    )\n",
            "                    (4): ReLU(inplace=True)\n",
            "                    (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                  )\n",
            "                )\n",
            "                (4): ReLU(inplace=True)\n",
            "                (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "              )\n",
            "            )\n",
            "            (4): ReLU(inplace=True)\n",
            "            (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "            (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "        (4): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 54409603\n",
            "DataParallel(\n",
            "  (module): UnetGenerator(\n",
            "    (model): UnetSkipConnectionBlock(\n",
            "      (model): Sequential(\n",
            "        (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "        (1): UnetSkipConnectionBlock(\n",
            "          (model): Sequential(\n",
            "            (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "            (1): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "            (2): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "            (3): UnetSkipConnectionBlock(\n",
            "              (model): Sequential(\n",
            "                (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                (1): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                (2): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                (3): UnetSkipConnectionBlock(\n",
            "                  (model): Sequential(\n",
            "                    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                    (1): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                    (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                    (3): UnetSkipConnectionBlock(\n",
            "                      (model): Sequential(\n",
            "                        (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                        (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                        (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                        (3): UnetSkipConnectionBlock(\n",
            "                          (model): Sequential(\n",
            "                            (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                            (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                            (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                            (3): UnetSkipConnectionBlock(\n",
            "                              (model): Sequential(\n",
            "                                (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                                (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                                (2): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                                (3): UnetSkipConnectionBlock(\n",
            "                                  (model): Sequential(\n",
            "                                    (0): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "                                    (1): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                                    (2): ReLU(inplace=True)\n",
            "                                    (3): ConvTranspose2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                                    (4): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                                  )\n",
            "                                )\n",
            "                                (4): ReLU(inplace=True)\n",
            "                                (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                                (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                              )\n",
            "                            )\n",
            "                            (4): ReLU(inplace=True)\n",
            "                            (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                            (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                          )\n",
            "                        )\n",
            "                        (4): ReLU(inplace=True)\n",
            "                        (5): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                        (6): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                      )\n",
            "                    )\n",
            "                    (4): ReLU(inplace=True)\n",
            "                    (5): ConvTranspose2d(1024, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "                  )\n",
            "                )\n",
            "                (4): ReLU(inplace=True)\n",
            "                (5): ConvTranspose2d(512, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "                (6): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "              )\n",
            "            )\n",
            "            (4): ReLU(inplace=True)\n",
            "            (5): ConvTranspose2d(256, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "            (6): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "          )\n",
            "        )\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): ConvTranspose2d(128, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "        (4): Tanh()\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 54409603\n",
            "DataParallel(\n",
            "  (module): NLayerDiscriminator(\n",
            "    (model): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "      (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 2764737\n",
            "DataParallel(\n",
            "  (module): NLayerDiscriminator(\n",
            "    (model): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "      (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "      (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(2, 2))\n",
            "      (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "      (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
            "      (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "      (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(2, 2))\n",
            "    )\n",
            "  )\n",
            ")\n",
            "Total number of parameters: 2764737\n",
            "-----------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = CycleGANModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oTxcpe2_3Tl",
        "outputId": "dcbbcf51-c006-4768-98e6-a5c74b09ff41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1016 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "100%|| 1016/1016 [03:14<00:00,  5.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 0, iters 1016\n",
            "End of epoch 0 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 1 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 2 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 3 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 92%|| 935/1016 [02:58<00:15,  5.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 4, total_steps 5000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 4 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 5, iters 6096\n",
            "End of epoch 5 / 100 \t Time Taken: 196 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 6 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 7 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 8 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 84%| | 855/1016 [02:42<00:30,  5.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 9, total_steps 10000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 9 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 10, iters 11176\n",
            "End of epoch 10 / 100 \t Time Taken: 196 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 11 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 12 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 13 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 76%|  | 775/1016 [02:27<00:45,  5.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 14, total_steps 15000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 14 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 15, iters 16256\n",
            "End of epoch 15 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 16 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 17 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 18 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 68%|   | 695/1016 [02:12<01:01,  5.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 19, total_steps 20000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 19 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 20, iters 21336\n",
            "End of epoch 20 / 100 \t Time Taken: 196 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 21 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 22 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 23 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 61%|    | 615/1016 [01:57<01:16,  5.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 24, total_steps 25000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 24 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 25, iters 26416\n",
            "End of epoch 25 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 26 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 27 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 28 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 53%|    | 535/1016 [01:41<01:31,  5.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 29, total_steps 30000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 29 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 30, iters 31496\n",
            "End of epoch 30 / 100 \t Time Taken: 196 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 31 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 32 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 33 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 45%|     | 455/1016 [01:26<01:47,  5.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 34, total_steps 35000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 34 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 35, iters 36576\n",
            "End of epoch 35 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 36 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 37 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 38 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 37%|      | 375/1016 [01:11<02:01,  5.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 39, total_steps 40000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 39 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 40, iters 41656\n",
            "End of epoch 40 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 41 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 42 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 43 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 29%|       | 295/1016 [00:56<02:17,  5.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 44, total_steps 45000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 44 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 45, iters 46736\n",
            "End of epoch 45 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:14<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 46 / 100 \t Time Taken: 194 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 47 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 48 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|        | 215/1016 [00:41<02:32,  5.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 49, total_steps 50000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:16<00:00,  5.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 49 / 100 \t Time Taken: 196 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:14<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 50, iters 51816\n",
            "End of epoch 50 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:14<00:00,  5.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 51 / 100 \t Time Taken: 194 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:14<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 52 / 100 \t Time Taken: 194 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:14<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 53 / 100 \t Time Taken: 194 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 13%|        | 135/1016 [00:25<02:47,  5.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 54, total_steps 55000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 54 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 55, iters 56896\n",
            "End of epoch 55 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 56 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 57 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 58 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|         | 55/1016 [00:10<03:02,  5.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 59, total_steps 60000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 59 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 60, iters 61976\n",
            "End of epoch 60 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 61 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 62 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 98%|| 991/1016 [03:08<00:04,  5.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 63, total_steps 65000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 63 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 64 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 65, iters 67056\n",
            "End of epoch 65 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 66 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 67 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 90%| | 911/1016 [02:53<00:20,  5.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 68, total_steps 70000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 68 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 69 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 70, iters 72136\n",
            "End of epoch 70 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 71 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 72 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 82%| | 831/1016 [02:38<00:35,  5.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 73, total_steps 75000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 73 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 74 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 75, iters 77216\n",
            "End of epoch 75 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 76 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 77 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 74%|  | 751/1016 [02:23<00:50,  5.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 78, total_steps 80000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 78 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 79 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 80, iters 82296\n",
            "End of epoch 80 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 81 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 82 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 66%|   | 671/1016 [02:07<01:05,  5.26it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 83, total_steps 85000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 83 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 84 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 85, iters 87376\n",
            "End of epoch 85 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 86 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 87 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 58%|    | 591/1016 [01:52<01:21,  5.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 88, total_steps 90000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 88 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 89 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 90, iters 92456\n",
            "End of epoch 90 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 91 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 92 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|     | 511/1016 [01:37<01:36,  5.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 93, total_steps 95000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 93 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 94 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the model at the end of epoch 95, iters 97536\n",
            "End of epoch 95 / 100 \t Time Taken: 197 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 96 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 97 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 42%|     | 431/1016 [01:22<01:51,  5.25it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saving the latest model (epoch 98, total_steps 100000)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:15<00:00,  5.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 98 / 100 \t Time Taken: 195 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|| 1016/1016 [03:13<00:00,  5.24it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "End of epoch 99 / 100 \t Time Taken: 193 sec\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "total_steps = 0 \n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  epoch_start_time = time.time()\n",
        "  loop = tqdm(dataset, leave=True)\n",
        "  for i, data in enumerate(loop):\n",
        "    iter_start_time = time.time()\n",
        "    total_steps += BATCH_SIZE\n",
        "    epoch_iter = total_steps - dataset_size * (epoch - 1)\n",
        "    model.set_input(data)\n",
        "    model.optimize_parameters(epoch)\n",
        "\n",
        "    if total_steps % 5000 == 0:\n",
        "      print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
        "      model.save_networks('latest')\n",
        "    \n",
        "  if epoch % 5 == 0:\n",
        "    print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))\n",
        "    model.save_networks('latest')\n",
        "    model.save_networks(epoch)\n",
        "\n",
        "  print('End of epoch %d / %d \\t Time Taken: %d sec' % (epoch, NUM_EPOCHS, time.time() - epoch_start_time))\n",
        "\n",
        "  if epoch == NUM_EPOCHS:\n",
        "    model.update_learning_rate()\n",
        "  elif epoch == (NUM_EPOCHS + 20):\n",
        "    model.update_learning_rate()\n",
        "  elif epoch == (NUM_EPOCHS + 70):\n",
        "    model.update_learning_rate()  \n",
        "  elif epoch == (NUM_EPOCHS + 90):\n",
        "    model.update_learning_rate()\n",
        "    model.update_learning_rate()\n",
        "    model.update_learning_rate()\n",
        "    model.update_learning_rate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "s--bX2LnK9pg"
      },
      "outputs": [],
      "source": [
        "def CreateTestLoader():\n",
        "  test_loader = CustomDatasetTestLoader()\n",
        "  print(test_loader.name())\n",
        "  test_loader.initialize()\n",
        "  return test_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "KhWwkoNWK9p-"
      },
      "outputs": [],
      "source": [
        "class CustomDatasetTestLoader():\n",
        "    def name(self):\n",
        "        return 'CustomDatasetTestLoader'\n",
        "\n",
        "    def initialize(self):\n",
        "        self.dataset = UnalignedDataset(\"/content/drive/MyDrive/final_dataset/testA\", \"/content/drive/MyDrive/final_dataset/testB\")\n",
        "        self.dataloader = torch.utils.data.DataLoader(\n",
        "            self.dataset,\n",
        "            batch_size=1,\n",
        "            shuffle=not True,\n",
        "            num_workers=1\n",
        "        )\n",
        "\n",
        "    def load_data(self):\n",
        "        return self.dataloader\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.dataset), float(\"inf\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "R5uBTAeRfosn"
      },
      "outputs": [],
      "source": [
        "name = \"enlighten\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "KvzV0HrbRd3_"
      },
      "outputs": [],
      "source": [
        "def save_image(visuals, img_path):\n",
        "  for label, image_numpy in visuals.items():\n",
        "    image_name = '%s_%s.png' % (name, label)\n",
        "    save_path = os.path.join(image_path, image_name)\n",
        "    image_pil = Image.fromarray(image_numpy)\n",
        "    image_pil.save(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loader = CreateTestLoader()\n",
        "testset = test_loader.load_data()\n",
        "print(len(testset))"
      ],
      "metadata": {
        "id": "Tjj5vZE9tPWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOetg8QCFoyj"
      },
      "outputs": [],
      "source": [
        "model.setup()  \n",
        "for i, data in enumerate(testset):\n",
        "  model.set_input(data)\n",
        "  visuals = model.predict()\n",
        "  img_path = model.get_image_paths()\n",
        "  print('process image... %s ' % img_path)\n",
        "  save_image(visuals, img_path)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "EnlightenGAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}