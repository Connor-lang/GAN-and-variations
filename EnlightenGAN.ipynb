{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EnlightenGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sys\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "from torch.autograd import Variable\n",
        "import itertools\n",
        "from collections import OrderedDict\n",
        "import time\n",
        "import functools\n",
        "from torch.nn import init\n",
        "from abc import ABC, abstractmethod"
      ],
      "metadata": {
        "id": "I5PzzuVpEyHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBD2zRS2rsGz"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 1\n",
        "GPU_IDS = [i for i in range(torch.cuda.device_count())]\n",
        "DEVICE = torch.device('cuda:{}'.format(GPU_IDS[0])) if GPU_IDS else torch.device('cpu')\n",
        "LEARNING_RATE = 1e-5\n",
        "LAMBDA_IDENTITY = 0.5\n",
        "LAMBDA_CYCLE = 10\n",
        "NUM_WORKERS = 2\n",
        "NUM_EPOCHS = 10\n",
        "LOAD_MODEL = False\n",
        "SAVE_MODEL = True\n",
        "CHECKPOINT_GEN_H = \"genh.pth.tar\"\n",
        "CHECKPOINT_GEN_Z = \"genz.pth.tar\"\n",
        "CHECKPOINT_CRITIC_H = \"critich.pth.tar\"\n",
        "CHECKPOINT_CRITIC_Z = \"criticz.pth.tar\"\n",
        "\n",
        "IMG_EXTENSIONS = [\n",
        "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
        "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP',\n",
        "]\n",
        "\n",
        "if (len(GPU_IDS) > 0):\n",
        "  torch.cuda.set_device(f'cuda:{GPU_IDS[0]}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_transform():\n",
        "  transform_list = []\n",
        "  zoom = 1 + 0.1 * random.randint(0, 4)\n",
        "  osize = [int(400 * zoom), int(600 * zoom)]\n",
        "  transform_list.append(transforms.Resize(osize, transforms.functional.InterpolationMode.BICUBIC))\n",
        "  transform_list.append(transforms.RandomCrop(256))\n",
        "  transform_list.append(transforms.RandomHorizontalFlip())\n",
        "  transform_list += [transforms.ToTensor(),\n",
        "                       transforms.Normalize((0.5, 0.5, 0.5),\n",
        "                                            (0.5, 0.5, 0.5))]\n",
        "  return transforms.Compose(transform_list)"
      ],
      "metadata": {
        "id": "kYpWsT_BQNgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)"
      ],
      "metadata": {
        "id": "zrt5WV54LEsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def store_dataset(dir):\n",
        "  images = []\n",
        "  all_path = []\n",
        "  assert os.path.isdir(dir), '%s is not a valid directory' %dir\n",
        "\n",
        "  for root, _, fnames in sorted(os.walk(dir)):\n",
        "    for fname in fnames: \n",
        "      if is_image_file(fname):\n",
        "        path = os.path.join(root, fname)\n",
        "        img = Image.open(path).convert('RGB')\n",
        "        images.append(img)\n",
        "        all_path.append(path)\n",
        "  return images, all_path"
      ],
      "metadata": {
        "id": "k2V6GLzWKgdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CreateDataLoader():\n",
        "  data_loader = CustomDatasetDataLoader()\n",
        "  print(data_loader.name())\n",
        "  data_loader.initialize()\n",
        "  return data_loader"
      ],
      "metadata": {
        "id": "jkKEEXpWGqXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_ids = \"0\"\n",
        "str_ids = gpu_ids.split(',')\n",
        "gpu_ids = []\n",
        "for str_id in str_ids:\n",
        "  id = int(str_id)\n",
        "  if id >= 0:\n",
        "    gpu_ids.append(id)\n",
        "if(len(gpu_ids)) > 0:\n",
        "  torch.cuda.set_device(gpu_ids[0])"
      ],
      "metadata": {
        "id": "XygFw1NnKsBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomDatasetDataLoader():\n",
        "    def name(self):\n",
        "        return 'CustomDatasetDataLoader'\n",
        "\n",
        "    def initialize(self):\n",
        "        self.dataset = UnalignedDataset(\"/content/dataset/trainA\", \"/content/dataset/trainB\")\n",
        "        self.dataloader = torch.utils.data.DataLoader(\n",
        "            self.dataset,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=not True,\n",
        "            num_workers=NUM_WORKERS\n",
        "        )\n",
        "\n",
        "    def load_data(self):\n",
        "        return self.dataloader\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.dataset), float(\"inf\"))"
      ],
      "metadata": {
        "id": "WA1Pi7wAHBdo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnalignedDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, dir_A, dir_B):\n",
        "        self.dir_A = dir_A\n",
        "        self.dir_B = dir_B\n",
        "        self.transform = get_transform()\n",
        "\n",
        "        self.A_imgs, self.A_paths = store_dataset(self.dir_A)\n",
        "        self.B_imgs, self.B_paths = store_dataset(self.dir_B)\n",
        "        self.length_dataset = max(len(self.A_imgs), len(self.B_imgs))\n",
        "        self.A_size = len(self.A_paths)\n",
        "        self.B_size = len(self.B_paths)\n",
        "\n",
        "  def __len__(self):\n",
        "      return self.length_dataset\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "      A_img = self.A_imgs[index % self.A_size]\n",
        "      B_img = self.B_imgs[index % self.B_size]\n",
        "      A_path = self.A_paths[index % self.A_size]\n",
        "      B_path = self.B_paths[index % self.B_size]\n",
        "\n",
        "      A_img = self.transform(A_img)\n",
        "      B_img = self.transform(B_img)\n",
        "\n",
        "      input_img = A_img\n",
        "      B_img = (B_img + 1)/2.\n",
        "      B_img = (B_img - torch.min(B_img))/(torch.max(B_img) - torch.min(B_img))\n",
        "      B_img = B_img * 2. - 1\n",
        "      r, g, b = input_img[0] + 1, input_img[1] + 1, input_img[2] + 1\n",
        "      A_gray = 1. - (0.299*r+0.587*g+0.114*b)/2.\n",
        "      A_gray = torch.unsqueeze(A_gray, 0)\n",
        "\n",
        "      return {'A': A_img, 'B': B_img, 'A_gray': A_gray, 'input_img': input_img,\n",
        "                'A_paths': A_path, 'B_paths': B_path}"
      ],
      "metadata": {
        "id": "up7RsCESHoEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_norm_layer(norm_type='instance'):\n",
        "    if norm_type == 'batch':\n",
        "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True, track_running_stats=True)\n",
        "    elif norm_type == 'instance':\n",
        "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False, track_running_stats=False)\n",
        "    else:\n",
        "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
        "    return norm_layer"
      ],
      "metadata": {
        "id": "Y9H70wfihgi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(net, init_type='normal', init_gain=0.02):\n",
        "    def init_func(m): \n",
        "        classname = m.__class__.__name__\n",
        "        if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
        "            if init_type == 'normal':\n",
        "                init.normal_(m.weight.data, 0.0, init_gain)\n",
        "            elif init_type == 'xavier':\n",
        "                init.xavier_normal_(m.weight.data, gain=init_gain)\n",
        "            elif init_type == 'kaiming':\n",
        "                init.kaiming_normal_(m.weight.data, a=0, mode='fan_in')\n",
        "            elif init_type == 'orthogonal':\n",
        "                init.orthogonal_(m.weight.data, gain=init_gain)\n",
        "            else:\n",
        "                raise NotImplementedError('initialization method [%s] is not implemented' % init_type)\n",
        "            if hasattr(m, 'bias') and m.bias is not None:\n",
        "                init.constant_(m.bias.data, 0.0)\n",
        "        elif classname.find('BatchNorm2d') != -1:  \n",
        "            init.normal_(m.weight.data, 1.0, init_gain)\n",
        "            init.constant_(m.bias.data, 0.0)\n",
        "\n",
        "    print('initialize network with %s' % init_type)\n",
        "    net.apply(init_func)  "
      ],
      "metadata": {
        "id": "mAStqgdBhiv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_net(net, init_type='normal', init_gain=0.02):\n",
        "    if len(GPU_IDS) > 0:\n",
        "        assert(torch.cuda.is_available())\n",
        "        net.to(GPU_IDS[0])\n",
        "        net = torch.nn.DataParallel(net, device_ids=[0])  \n",
        "    init_weights(net, init_type, init_gain=init_gain)\n",
        "    return net"
      ],
      "metadata": {
        "id": "EaRcxFBRgXZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_G(input_nc, output_nc, ngf, norm='batch', use_dropout=False, init_type='normal', init_gain=0.02):\n",
        "  net = None\n",
        "  norm_layer = get_norm_layer(norm_type=norm)\n",
        "  net = UnetGenerator(input_nc, output_nc, 8, ngf, norm_layer=norm_layer, use_dropout=use_dropout)\n",
        "  return init_net(net, init_type, init_gain)"
      ],
      "metadata": {
        "id": "HCeItyregIpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_D(input_nc, ndf, n_layers_D=3, norm='batch', init_type='normal', init_gain=0.02):\n",
        "  net = None\n",
        "  norm_layer = get_norm_layer(norm_type=norm)\n",
        "  net = NLayerDiscriminator(input_nc, ndf, n_layers=3, norm_layer=norm_layer)\n",
        "  return init_net(net, init_type, init_gain)"
      ],
      "metadata": {
        "id": "xM9HjAyIv2CP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnetSkipConnectionBlock(nn.Module):\n",
        "    def __init__(self, outer_nc, inner_nc, input_nc=None,\n",
        "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
        "        super(UnetSkipConnectionBlock, self).__init__()\n",
        "        self.outermost = outermost\n",
        "        if type(norm_layer) == functools.partial:\n",
        "            use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "        else:\n",
        "            use_bias = norm_layer == nn.InstanceNorm2d\n",
        "        if input_nc is None:\n",
        "            input_nc = outer_nc\n",
        "        downconv = nn.Conv2d(outer_nc, inner_nc, kernel_size=4,\n",
        "                             stride=2, padding=1, bias=use_bias)\n",
        "        downrelu = nn.LeakyReLU(0.2, True)\n",
        "        downnorm = norm_layer(inner_nc)\n",
        "        uprelu = nn.ReLU(True)\n",
        "        upnorm = norm_layer(outer_nc)\n",
        "\n",
        "        if outermost:\n",
        "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
        "                                        kernel_size=4, stride=2,\n",
        "                                        padding=1)\n",
        "            down = [downconv]\n",
        "            up = [uprelu, upconv, nn.Tanh()]\n",
        "            model = down + [submodule] + up\n",
        "        elif innermost:\n",
        "            upconv = nn.ConvTranspose2d(inner_nc, outer_nc,\n",
        "                                        kernel_size=4, stride=2,\n",
        "                                        padding=1, bias=use_bias)\n",
        "            down = [downrelu, downconv]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "            model = down + up\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(inner_nc * 2, outer_nc,\n",
        "                                        kernel_size=4, stride=2,\n",
        "                                        padding=1, bias=use_bias)\n",
        "            down = [downrelu, downconv, downnorm]\n",
        "            up = [uprelu, upconv, upnorm]\n",
        "\n",
        "            if use_dropout:\n",
        "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
        "            else:\n",
        "                model = down + [submodule] + up\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:\n",
        "            return torch.cat([x, self.model(x)], 1)"
      ],
      "metadata": {
        "id": "JiKYFtEGExl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipModule(nn.Module):\n",
        "    def __init__(self, submodule):\n",
        "        super(SkipModule, self).__init__()\n",
        "        self.submodule = submodule\n",
        "\n",
        "    def forward(self, x):\n",
        "        latent = self.submodule(x)\n",
        "        return 0.8*x + latent, latent"
      ],
      "metadata": {
        "id": "vMRy5PZfmemt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UnetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc, num_downs, ngf=64,\n",
        "                 norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
        "        super(UnetGenerator, self).__init__()\n",
        "\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=None, norm_layer=norm_layer, innermost=True)\n",
        "        for i in range(num_downs - 5):\n",
        "            unet_block = UnetSkipConnectionBlock(ngf * 8, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer, use_dropout=use_dropout)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 4, ngf * 8, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf * 2, ngf * 4, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(ngf, ngf * 2, input_nc=None, submodule=unet_block, norm_layer=norm_layer)\n",
        "        self.model = UnetSkipConnectionBlock(output_nc, ngf, input_nc=input_nc, submodule=unet_block, outermost=True, norm_layer=norm_layer)\n",
        "\n",
        "    def forward(self, input):\n",
        "      return self.model(input)"
      ],
      "metadata": {
        "id": "4LW7elgPeFeE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NLayerDiscriminator(nn.Module):\n",
        "  def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d):\n",
        "    super(NLayerDiscriminator, self).__init__()\n",
        "    if type(norm_layer) == functools.partial:\n",
        "      use_bias = norm_layer.func == nn.InstanceNorm2d\n",
        "    else:\n",
        "      use_bias = norm_layer == nn.InstanceNorm2d\n",
        "\n",
        "    kw = 4\n",
        "    padw = int(np.ceil((kw-1)/2))\n",
        "    sequence = [nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]\n",
        "\n",
        "    nf_mult = 1\n",
        "    nf_mult_prev = 1\n",
        "    for n in range(1, n_layers):\n",
        "      nf_mult_prev = nf_mult\n",
        "      nf_mult = min(2**n, 8)\n",
        "      sequence += [\n",
        "          nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=2, padding=padw, bias=use_bias),\n",
        "          norm_layer(ndf * nf_mult),\n",
        "          nn.LeakyReLU(0.2, True)\n",
        "      ]\n",
        "\n",
        "    nf_mult_prev = nf_mult\n",
        "    nf_mult = min(2**n_layers, 8)\n",
        "    sequence += [\n",
        "        nn.Conv2d(ndf * nf_mult_prev, ndf * nf_mult, kernel_size=kw, stride=1, padding=padw, bias=use_bias),\n",
        "        norm_layer(ndf * nf_mult),\n",
        "        nn.LeakyReLU(0.2, True)\n",
        "    ]\n",
        "\n",
        "    sequence += [nn.Conv2d(ndf * nf_mult, 1, kernel_size=kw, stride=1, padding=padw)]\n",
        "    \n",
        "    self.model = nn.Sequential(*sequence)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "VmBvu-JYi1Ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GANLoss(nn.Module):\n",
        "    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0):\n",
        "        super(GANLoss, self).__init__()\n",
        "        self.register_buffer('real_label', torch.tensor(target_real_label))\n",
        "        self.register_buffer('fake_label', torch.tensor(target_fake_label))\n",
        "        if use_lsgan:\n",
        "            self.loss = nn.MSELoss()\n",
        "        else:\n",
        "            self.loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def get_target_tensor(self, prediction, target_is_real):\n",
        "        if target_is_real:\n",
        "            target_tensor = self.real_label\n",
        "        else:\n",
        "            target_tensor = self.fake_label\n",
        "        return target_tensor.expand_as(prediction)\n",
        "\n",
        "    def __call__(self, prediction, target_is_real):\n",
        "        target_tensor = self.get_target_tensor(prediction, target_is_real)\n",
        "        return self.loss(prediction, target_tensor)"
      ],
      "metadata": {
        "id": "_7IdwlCpsmYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ImagePool():\n",
        "    def __init__(self, pool_size):\n",
        "        self.pool_size = pool_size\n",
        "        if self.pool_size > 0:\n",
        "            self.num_imgs = 0\n",
        "            self.images = []\n",
        "\n",
        "    def query(self, images):\n",
        "        if self.pool_size == 0:\n",
        "            return images\n",
        "        return_images = []\n",
        "        for image in images.data:\n",
        "            image = torch.unsqueeze(image, 0)\n",
        "            if self.num_imgs < self.pool_size:\n",
        "                self.num_imgs = self.num_imgs + 1\n",
        "                self.images.append(image)\n",
        "                return_images.append(image)\n",
        "            else:\n",
        "                p = random.uniform(0, 1)\n",
        "                if p > 0.5:\n",
        "                    random_id = random.randint(0, self.pool_size-1)\n",
        "                    tmp = self.images[random_id].clone()\n",
        "                    self.images[random_id] = image\n",
        "                    return_images.append(tmp)\n",
        "                else:\n",
        "                    return_images.append(image)\n",
        "        return_images = Variable(torch.cat(return_images, 0))\n",
        "        return return_images"
      ],
      "metadata": {
        "id": "Vq8SWObrtEYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_network(net):\n",
        "    num_params = 0\n",
        "    for param in net.parameters():\n",
        "        num_params += param.numel()\n",
        "    print(net)\n",
        "    print('Total number of parameters: %d' % num_params)"
      ],
      "metadata": {
        "id": "zCj3-7j6xFt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor2im(image_tensor, imtype=np.uint8):\n",
        "    if not isinstance(image_tensor, np.ndarray):\n",
        "        if isinstance(image_tensor, torch.Tensor):  \n",
        "            image_tensor = image_tensor.data\n",
        "        else:\n",
        "            return image_tensor\n",
        "        image_numpy = image_tensor[0].cpu().float().numpy()  \n",
        "        if image_numpy.shape[0] == 1:  \n",
        "            image_numpy = np.tile(image_numpy, (3, 1, 1))\n",
        "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0  \n",
        "    else:  \n",
        "        image_numpy = image_tensor\n",
        "    return image_numpy.astype(imtype)"
      ],
      "metadata": {
        "id": "8cOA4tOsK_Kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = CreateDataLoader()\n",
        "dataset = data_loader.load_data()\n",
        "dataset_size = len(data_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMtPlsNTLJxt",
        "outputId": "0aed39bd-a478-4ea6-b20e-96031d38f713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomDatasetDataLoader\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('#training images = %d' % dataset_size)"
      ],
      "metadata": {
        "id": "8oJ6_SV0eTzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3330fa27-da80-4bb9-f8f7-bd97b0e0e36d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#training images = 1016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CycleGANModel():\n",
        "  def __init__(self, batchSize = 1, fineSize = 256, input_nc=3, output_nc=3):\n",
        "    nb = batchSize\n",
        "    size = fineSize\n",
        "    self.netG_A = define_G(input_nc = 3, output_nc = 3, ngf = 64, norm = 'instance', use_dropout = not True, init_type = 'normal', init_gain = 0.02)\n",
        "    self.netG_B = define_G(input_nc = 3, output_nc = 3, ngf = 64, norm = 'instance', use_dropout = not True, init_type = 'normal', init_gain = 0.02)\n",
        "   \n",
        "    self.netD_A = define_D(input_nc =3, ndf=64, n_layers_D=3, norm='instance', init_type='normal', init_gain=0.2)\n",
        "    self.netD_B = define_D(input_nc =3, ndf=64, n_layers_D=3, norm='instance', init_type='normal', init_gain=0.2)\n",
        "    self.fake_A_pool = ImagePool(50)\n",
        "    self.fake_B_pool = ImagePool(50)\n",
        "\n",
        "    self.criterionGAN = GANLoss(use_lsgan = True).to(DEVICE)\n",
        "    self.criterionCycle = torch.nn.L1Loss()\n",
        "    self.criterionL1 = torch.nn.L1Loss()\n",
        "    self.criterionIdt = torch.nn.L1Loss()\n",
        "\n",
        "    self.optimizer_G = torch.optim.Adam(itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()), \n",
        "                                        lr = LEARNING_RATE, betas = (0.5, 0.999))\n",
        "    self.optimizer_D = torch.optim.Adam(itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()), \n",
        "                                        lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "\n",
        "    \n",
        "    print('---------- Networks initialized -------------')\n",
        "    print_network(self.netG_A)\n",
        "    print_network(self.netG_B)\n",
        "    print_network(self.netD_A)\n",
        "    print_network(self.netD_B)\n",
        "    print('-----------------------------------------------')\n",
        "\n",
        "  def set_input(self, input):\n",
        "    self.real_A = input['A'].to(DEVICE)\n",
        "    self.real_B = input['B'].to(DEVICE)\n",
        "    self.image_paths = input['A_paths']\n",
        "    \n",
        "\n",
        "  def forward(self):\n",
        "    self.fake_B = self.netG_A(self.real_A)\n",
        "    self.rec_A = self.netG_B(self.fake_B)\n",
        "    self.fake_A = self.netG_B(self.real_B)\n",
        "    self.rec_B = self.netG_A(self.fake_A)\n",
        "\n",
        "  def predict(self):\n",
        "    self.real_A = Variable(self.input_A, volatile=True)\n",
        "    if self.opt.skip == 1:\n",
        "        self.fake_B, self.latent_real_A = self.netG_A.forward(self.real_A)\n",
        "    else:\n",
        "        self.fake_B = self.netG_A.forward(self.real_A)\n",
        "    self.rec_A = self.netG_B.forward(self.fake_B)\n",
        "\n",
        "    real_A = tensor2im(self.real_A.data)\n",
        "    fake_B = tensor2im(self.fake_B.data)\n",
        "    rec_A = tensor2im(self.rec_A.data)\n",
        "    return OrderedDict([('real_A', real_A), ('fake_B', fake_B), (\"rec_A\", rec_A)])\n",
        "\n",
        "  def get_image_paths(self):\n",
        "        return self.image_paths\n",
        "  \n",
        "  def backward_D_basic(self, netD, real, fake):\n",
        "    \n",
        "    pred_real = netD.forward(real)\n",
        "    loss_D_real = self.criterionGAN(pred_real, True)\n",
        "    \n",
        "    pred_fake = netD.forward(fake.detach())\n",
        "    loss_D_fake = self.criterionGAN(pred_fake, False)\n",
        "    \n",
        "    loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
        "\n",
        "    loss_D.backward()\n",
        "    return loss_D\n",
        "\n",
        "  def backward_D_A(self):\n",
        "      fake_B = self.fake_B_pool.query(self.fake_B)\n",
        "      self.loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n",
        "\n",
        "  def backward_D_B(self):\n",
        "      fake_A = self.fake_A_pool.query(self.fake_A)\n",
        "      self.loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n",
        "\n",
        "  def backward_G(self, epoch):\n",
        "    lambda_idt = 0.0\n",
        "    lambda_A = 10.0\n",
        "    lambda_B = 10.0\n",
        "    self.loss_idt_A = 0\n",
        "    self.loss_idt_B = 0\n",
        "\n",
        "    self.fake_B = self.netG_A.forward(self.real_A) \n",
        "    pred_fake = self.netD_A.forward(self.fake_B) \n",
        "    self.loss_G_A = self.criterionGAN(pred_fake, True) \n",
        "    self.L1_AB = self.criterionL1(self.fake_B, self.real_B) * 10.0\n",
        "\n",
        "    self.fake_A = self.netG_B.forward(self.real_B)\n",
        "    pred_fake = self.netD_B.forward(self.fake_A)\n",
        "\n",
        "    self.L1_BA = self.criterionL1(self.fake_A, self.real_A) * 10.0\n",
        "    self.loss_G_B = self.criterionGAN(pred_fake, True)\n",
        "\n",
        "    self.rec_A = self.netG_B.forward(self.fake_B)\n",
        "    self.loss_cycle_A = self.criterionCycle(self.rec_A, self.real_A) * lambda_A\n",
        "\n",
        "    self.rec_B = self.netG_A.forward(self.fake_A)\n",
        "    self.loss_cycle_B = self.criterionCycle(self.rec_B, self.real_B) * lambda_B\n",
        "\n",
        "    self.loss_G = self.loss_G_A + self.loss_G_B + self.loss_cycle_A + self.loss_cycle_B \n",
        "    \n",
        "    self.loss_G.backward()\n",
        "\n",
        "  def optimize_parameters(self, epoch):\n",
        "    \n",
        "    self.forward()\n",
        "\n",
        "    self.optimizer_G.zero_grad()\n",
        "    self.backward_G(epoch)\n",
        "    self.optimizer_G.step()\n",
        "    \n",
        "    self.optimizer_D_A.zero_grad()\n",
        "    self.backward_D_A()\n",
        "    self.optimizer_D_A.step()\n",
        "   \n",
        "    self.optimizer_D_B.zero_grad()\n",
        "    self.backward_D_B()\n",
        "    self.optimizer_D_B.step()\n",
        "\n",
        "  def get_current_errors(self):\n",
        "    D_A = self.loss_D_A.data[0]\n",
        "    G_A = self.loss_G_A.data[0]\n",
        "    Cyc_A = self.loss_cycle_A.data[0]\n",
        "    D_B = self.loss_D_B.data[0]\n",
        "    G_B = self.loss_G_B.data[0]\n",
        "    Cyc_B = self.loss_cycle_B.data[0]\n",
        "    if self.lambda_A > 0.0:\n",
        "        return OrderedDict([('D_A', D_A), ('G_A', G_A), ('Cyc_A', Cyc_A),\n",
        "                            ('D_B', D_B), ('G_B', G_B), ('Cyc_B', Cyc_B)])\n",
        "    else:\n",
        "        return OrderedDict([('D_A', D_A), ('G_A', G_A), \n",
        "                            ('D_B', D_B), ('G_B', G_B)])\n",
        "        \n",
        "  def get_current_visuals(self):\n",
        "    real_A = tensor2im(self.real_A.data)\n",
        "    fake_B = tensor2im(self.fake_B.data)\n",
        "    latent_real_A = tensor2im(self.latent_real_A.data)\n",
        "    real_B = tensor2im(self.real_B.data)\n",
        "    fake_A = tensor2im(self.fake_A.data)\n",
        "\n",
        "    rec_A = tensor2im(self.rec_A.data)\n",
        "    rec_B = tensor2im(self.rec_B.data)\n",
        "    latent_fake_A = tensor2im(self.latent_fake_A.data)\n",
        "    return OrderedDict([('real_A', real_A), ('fake_B', fake_B), ('latent_real_A', latent_real_A), ('rec_A', rec_A), \n",
        "                        ('real_B', real_B), ('fake_A', fake_A), ('rec_B', rec_B), ('latent_fake_A', latent_fake_A)])\n",
        "    \n",
        "  def load_networks(self, epoch): \n",
        "    for name in ['G_A', 'G_B']:\n",
        "      if isinstance(name, str):\n",
        "          load_filename = '%s_net_%s.pth' % (epoch, name)\n",
        "          load_path = os.path.join('/content/checkpoints', load_filename)\n",
        "          net = getattr(self, 'net' + name)\n",
        "          if isinstance(net, torch.nn.DataParallel):\n",
        "              net = net.module\n",
        "          print('loading the model from %s' % load_path)\n",
        "          state_dict = torch.load(load_path, map_location=str(DEVICE))\n",
        "          if hasattr(state_dict, '_metadata'):\n",
        "              del state_dict._metadata\n",
        "          net.load_state_dict(state_dict)\n",
        "    \n",
        "  def setup(self):\n",
        "    load_suffix = '5'\n",
        "    self.load_networks(load_suffix)\n",
        "  \n",
        "  def eval(self):\n",
        "    for name in self.model_names:\n",
        "      if isinstance(name, str):\n",
        "        net = getattr(self, 'net' + name)\n",
        "        net.eval()\n",
        "\n",
        "  def compute_visuals(self):\n",
        "    \"\"\"Calculate additional output images for visdom and HTML visualization\"\"\"\n",
        "    pass\n",
        "\n",
        "  def get_current_visuals(self):\n",
        "    \"\"\"Return visualization images. train.py will display these images with visdom, and save the images to a HTML\"\"\"\n",
        "    visual_ret = OrderedDict()\n",
        "    for name in ['real_A', 'fake_B', 'rec_A', 'real_B', 'fake_A', 'rec_B']:\n",
        "        if isinstance(name, str):\n",
        "            visual_ret[name] = getattr(self, name)\n",
        "    return visual_ret\n",
        "    \n",
        "  def test(self):\n",
        "    with torch.no_grad():\n",
        "      self.forward()\n",
        "      self.compute_visuals()\n",
        "    \n",
        "  def save_networks(self, epoch):\n",
        "    model_names = ['G_A', 'G_B', 'D_A', 'D_B']\n",
        "    for name in model_names:\n",
        "      if isinstance(name , str):\n",
        "        save_filename = '%s_net_%s.pth' % (epoch, name)\n",
        "        save_path = os.path.join('/content/checkpoints', save_filename)\n",
        "        net = getattr(self, 'net' + name)\n",
        "\n",
        "        if len(GPU_IDS) > 0 and torch.cuda.is_available():\n",
        "          torch.save(net.module.cpu().state_dict(), save_path)\n",
        "          net.cuda(GPU_IDS[0])\n",
        "        else:\n",
        "          torch.save(net.cpu().state_dict(), save_path)\n",
        "\n",
        "  def update_learning_rate(self):\n",
        "    lrd = 0.0001 / 100\n",
        "    lr = self.old_lr - lrd\n",
        "    for param_group in self.optimizer_D_A.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    for param_group in self.optimizer_D_B.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    for param_group in self.optimizer_G.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "\n",
        "    print('update learning rate: %f -> %f' % (self.old_lr, lr))\n",
        "    self.old_lr = lr"
      ],
      "metadata": {
        "id": "n2g8tlyykya3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CycleGANModel()"
      ],
      "metadata": {
        "id": "xSJFO1LW7fc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_steps = 0 \n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  epoch_start_time = time.time()\n",
        "  loop = tqdm(dataset, leave=True)\n",
        "  for i, data in enumerate(loop):\n",
        "    iter_start_time = time.time()\n",
        "    total_steps += BATCH_SIZE\n",
        "    epoch_iter = total_steps - dataset_size * (epoch - 1)\n",
        "    model.set_input(data)\n",
        "    model.optimize_parameters(epoch)\n",
        "\n",
        "    if total_steps % 5000 == 0:\n",
        "      print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
        "      model.save_networks('latest')\n",
        "    \n",
        "  if epoch % 5 == 0:\n",
        "    print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))\n",
        "    model.save_networks('latest')\n",
        "    model.save_networks(epoch)\n",
        "\n",
        "  print('End of epoch %d / %d \\t Time Taken: %d sec' % (epoch, NUM_EPOCHS, time.time() - epoch_start_time))\n",
        "\n",
        "  if epoch == NUM_EPOCHS:\n",
        "    model.update_learning_rate()\n",
        "  elif epoch == (NUM_EPOCHS + 20):\n",
        "    model.update_learning_rate()\n",
        "  elif epoch == (NUM_EPOCHS + 70):\n",
        "    model.update_learning_rate()\n",
        "  elif epoch == (NUM_EPOCHS + 90):\n",
        "    model.update_learning_rate()\n",
        "    model.update_learning_rate()\n",
        "    model.update_learning_rate()\n",
        "    model.update_learning_rate()\n"
      ],
      "metadata": {
        "id": "7oTxcpe2_3Tl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "outputId": "48f2c874-09e9-42e8-b20b-273d9acba650"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1016/1016 [03:38<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving the model at the end of epoch 0, iters 1016\n",
            "End of epoch 0 / 10 \t Time Taken: 222 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1016/1016 [03:38<00:00,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "End of epoch 1 / 10 \t Time Taken: 218 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 885/1016 [03:10<00:28,  4.64it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-3f844b555d79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mepoch_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_steps\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdataset_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtotal_steps\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m200\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-0800a2df9c78>\u001b[0m in \u001b[0;36moptimize_parameters\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;31m# self.optimizer_D.zero_grad()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_D_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_D_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_D_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-0800a2df9c78>\u001b[0m in \u001b[0;36mbackward_D_A\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbackward_D_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m       \u001b[0mfake_B\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_B_pool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfake_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_D_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_D_basic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetD_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_B\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbackward_D_B\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-0800a2df9c78>\u001b[0m in \u001b[0;36mbackward_D_basic\u001b[0;34m(self, netD, real, fake)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mloss_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_D_real\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_D_fake\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mloss_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss_D\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}